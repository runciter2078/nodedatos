+++
title = 'nodedatos - Semana 8, 2026'
date = 2026-02-19T15:04:09+00:00
draft = false
tags = ['newsletter', 'ia', '2026']
description = 'Newsletter semanal sobre inteligencia artificial'
+++

¿Puede la inteligencia artificial de frontera ser rentable, o estamos ante una burbuja de 650.000 millones de dólares en compromisos de inversión para 2026?

Esta semana, el sector de la IA ha puesto el foco en la rentabilidad unitaria de los modelos de vanguardia. El análisis conjunto de Epoch AI y Exponential View sobre GPT-5 desvela un panorama mixto: costes por token que rondan los 0,30 dólares en entrenamiento y 0,10 en inferencia, pero con ingresos por suscripción que apenas cubren el gasto si no se escala masivamente. Me entusiasma ver cómo empresas como OpenAI buscan salidas con hardware alternativo como los chips de Cerebras, que aceleran la generación de código un 15x. Sin embargo, mantengo los pies en la tierra: sin avances drásticos en eficiencia, estos modelos seguirán quemando capital como si no hubiera mañana.

Esto no es un detalle menor. Revela una tensión central en la industria: mientras Alibaba lanza Qwen3.5, un Mixture of Experts (MoE), una arquitectura que activa solo una fracción de los parámetros en cada consulta, de 397.000 millones con solo 17.000 millones activos, y DeepMind estrena Lyria 3 para generar música a partir de fotos, la pregunta clave es si estos saltos técnicos traducen en beneficios reales. Los modelos abiertos como GLM-5 intentan ir a rebufo, pero perpetúan un ciclo eterno de ponerse al día.

En resumen, innovamos a ritmos frenéticos, pero la sostenibilidad económica definirá ganadores y perdedores. ¿Estás listo para un 2026 donde la eficiencia sea el nuevo rey?

## Lo esencial en 5 puntos

**OpenAI despliega GPT-5.3-Codex en chips de Cerebras, evitando Nvidia.**  
Este modelo de codificación genera más de 1.000 tokens por segundo, un 15x más rápido que su predecesor. Corre en hardware del tamaño de una placa, lo que reduce dependencia de GPUs tradicionales y abre puertas a inferencia más barata. Importa porque acelera el desarrollo de software con IA, pero cuestiona el dominio de Nvidia.

**Alibaba lanza Qwen3.5, primeros modelos multimodales nativos para agentes.**  
La serie incluye una versión de código abierto (Qwen3.5-397B-A17B, MoE eficiente) y otra propietaria, ambos con visión. Destacan en tareas de agentes que procesan imágenes y texto simultáneamente. Es un avance chino que presiona a Occidente en multimodalidad accesible.

**DeepMind presenta Lyria 3, genera música con letras y voces desde fotos o texto.**  
Integrado en la app Gemini, crea pistas de 30 segundos complejas, manejando formas de onda audio con precisión creativa. Supera límites previos en síntesis musical generativa. Revoluciona la producción artística, aunque plantea retos éticos en derechos de autor.

**Google actualiza Gemini 3 Deep Think para ciencia y razonamiento avanzado.**  
Este modo especializado resuelve problemas de investigación moderna, ingeniería y ciencia. Mejora en benchmarks de razonamiento profundo. Ayuda a investigadores a escalar experimentos complejos, democratizando avances académicos.

**Análisis revela rentabilidad unitaria precaria para GPT-5.**  
Con 650.000 millones en inversión en infraestructura de grandes tecnológicas para 2026, los costes superan ingresos salvo en escalas masivas. Epoch AI calcula break-even en millones de usuarios premium. Expone vulnerabilidades económicas en la carrera por modelos frontera.

## Debates y fricciones

Los modelos abiertos como GLM-5 de Z.ai generan revuelo cada 4-6 meses, acercándose a los cerrados en benchmarks, pero Nathan Lambert (Interconnects) argumenta que están en un ponerse al día perpetuo: cierran brechas, pero los cerrados avanzan más rápido gracias a datos propietarios. ¿Innovación compartida o ilusión competitiva?

DeepMind cuestiona si los LLM exhiben señalización virtuosa (comportamientos morales superficiales) en roles como terapeutas o consejeros. Piden benchmarks rigurosos, equiparándolos a matemáticas o código. Críticos ven hype; defensores, necesidad de regulación ética.

Arvind Narayanan sostiene que la IA no abaratará servicios legales automáticamente: automatiza tareas simples, pero complejidad humana persiste, potenciando concentración de mercado.

## Producto y mercado

David Silver, veterano de DeepMind, capta 1.000 millones en ronda semilla para Ineffable Intelligence, enfocada en superinteligencia sin LLM. La mayor seed round histórica, en Londres, busca alternativas simbólicas.

OpenAI lanza "OpenAI for India": infraestructura local, herramientas empresariales y formación laboral para expandir acceso. NVIDIA impulsa misión india con Blackwell Ultra, reduciendo costes en agentes un 35x según SemiAnalysis.

## Investigación y técnica

Zyphra publica ZUNA, modelo base de 380 millones de parámetros para interfaces cerebro-computadora (BCI) no invasivas vía electroencefalograma (EEG). Usa autoencoder de difusión enmascarado para infilling de canales y superresolución, avanzando en texto-pensamiento.

OpenAI presenta GABRIEL, kit de código abierto que convierte texto cualitativo e imágenes en datos cuantitativos con GPT, escalando investigación social. GPT-5.2 deriva nueva fórmula para amplitud de gluones en física teórica, verificada académicamente.

NVIDIA Blackwell Ultra logra 50x mejor rendimiento y 35x menos costes en IA agentic, según InferenceX.

## Política, seguridad y sociedad

Conferencia Def Con veta a tres hackers vinculados a Epstein: Pablos Holman, Vincenzo Iozzo y Joichi Ito (ex MIT Media Lab). Motivo: conexiones reportadas con el financiero.

Brecha en fintech Figure expone datos de casi un millón de clientes: nombres, fechas de nacimiento, direcciones, teléfonos y emails. No afecta contraseñas ni finanzas directas.

Wired critica promesas de Big Tech: de 154 claims sobre IA climática, solo 25% cita investigación; 33% sin evidencia.

## Radar rápido

- **Interop 2026 arranca colaboración Apple-Google-Microsoft-Mozilla-Igalia**: Paridad en features web clave durante el año.
- **NVIDIA encuestada en telecom**: IA impulsa redes autónomas, ROI sube al 50% en adoptores.
- **VMware pierde usuarios post-Broadcom**: Dos años después, mayoría reduce huella por precios y lock-in.
- **IA legal no abarata servicios**: Automatiza lo simple, pero complejidad humana domina.
- **OpenAI evalúa Slack como producto**: Altman invita ideas en town hall; ¿agente en mensajería?.

## Cierre

¿Crees que la rentabilidad unitaria frenará la carrera por modelos más grandes, o la eficiencia como MoE la acelerará? Comparte tu visión en comentarios.

Sugerencia práctica: Prueba GABRIEL de OpenAI (openai.com/index/scaling-social-science-research). Convierte entrevistas o imágenes en datos cuantitativos escalables; ideal para investigadores sociales que quieren analizar miles de respuestas cualitativas sin esfuerzo manual.

## Fuentes

1. OpenAI - https://openai.com/index/introducing-gpt-5-3-codex-spark/
2. Qwen Blog - https://qwen.ai/blog?id=qwen3.5
3. Google DeepMind Blog - https://deepmind.google/blog/a-new-way-to-express-yourself-gemini-can-now-create-music/
4. Google DeepMind Blog - https://deepmind.google/blog/gemini-3-deep-think-advancing-science-research-and-engineering/
5. Epoch AI / Exponential View - https://www.exponentialview.co/p/x-raying-openais-unit-economics
6. OpenAI - https://openai.com/index/scaling-social-science-research
7. OpenAI - https://openai.com/index/new-result-theoretical-physics
8. NVIDIA Blog - https://blogs.nvidia.com/blog/data-blackwell-ultra-performance-lower-cost-agentic-ai/
9. MarkTechPost (Zyphra ZUNA) - https://www.marktechpost.com/2026/02/18/zyphra-releases-zuna-a-380m-parameter-bci-foundation-model-for-eeg-data-advancing-noninvasive-thought-to-text-development/
10. The Decoder (David Silver) - https://the-decoder.com/deepmind-veteran-david-silver-raises-1b-seed-round-to-build-superintelligence-without-llms/
11. OpenAI - https://openai.com/index/openai-for-india