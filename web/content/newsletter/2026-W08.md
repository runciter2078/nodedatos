+++
title = 'nodedatos - Semana 8, 2026'
date = 2026-02-18T12:39:58+00:00
draft = false
tags = ['newsletter', 'ia', '2026']
description = 'Newsletter semanal sobre inteligencia artificial'
+++

*Nuevos titanes en LLMs: coding ultrarrápido y agentes multimodales desafían el statu quo*

¿Y si esta semana marca el punto de no retorno en la carrera por modelos de IA que no solo piensan, sino que codifican a velocidades de vértigo? GLM-5, con sus 754.000 millones de parámetros bajo licencia MIT, irrumpe como el open-weights más colosal hasta la fecha, duplicando el tamaño de su predecesor. No es hype vacío: Z.ai lo ha subido a Hugging Face en 1,51 TB, listo para que cualquiera lo descargue y experimente. Me entusiasma porque democratiza la frontera; ya no es solo OpenAI o Google quienes dictan el ritmo.

Pero mantengamos los pies en la tierra. OpenAI contraataca con GPT-5.3-Codex-Spark, un modelo de coding 15 veces más rápido que su antecesor, rodando en chips del tamaño de una placa de Cerebras, sin Nvidia de por medio. Anthropic responde con Claude Sonnet 4.6, que iguala al Opus 4.5 pero a mitad de precio. ¿Innovación genuina o mera escalada de parámetros? Para mí, lo clave es el giro hacia agentes nativos multimodales, como Qwen3.5 de Alibaba: visión integrada y eficiencia en MoE que promete agentes que "ven" y actúan. Esto acelera la industria, pero ¿a qué costo en energía y unit economics? OpenAI ya gasta cientos de miles de millones; si no rentabilizan, el castillo de naipes tiembla.

De lo puntual a lo sistémico: estos lanzamientos no solo saturan Hugging Face, sino que redefinen el coding como agente engineering. Desarrolladores hablan de "Deep Blue", ese tedio existencial ante la IA que devora su oficio. ¿Estás listo para un mundo donde el código se genera en segundos, o temes el "cognitive debt" que deja atrás?

## Lo esencial en 5 puntos

**GLM-5 irrumpe con 754B parámetros open-source.** Z.ai lanza este titán MIT-licenciado, el doble de grande que GLM-4.7 (368B). Disponible en Hugging Face (1,51 TB), pasa de "vibe coding" a engineering agentic, superando SOTA en benchmarks abiertos. Importa porque acelera la experimentación sin pagar royalties.

**OpenAI estrena GPT-5.3-Codex-Spark en chips no-Nvidia.** Primera integración productiva con Cerebras: genera 1.000+ tokens/segundo, 15x más rápido que el anterior, con 128k contexto. En preview para ChatGPT Pro. Rompe la dependencia de Nvidia y acelera coding en tiempo real.

**Anthropic lanza Claude Sonnet 4.6, rival asequible de Opus.** Igual rendimiento que Opus 4.5 (noviembre 2025), pero a $3/$15 por millón de tokens (vs. $5/$25). Mejora en coding y razonamiento. Equilibra potencia y coste, ideal para escalado empresarial.

**Qwen3.5 de Alibaba apunta a agentes multimodales nativos.** Dos versiones: open-weights MoE de 397B-A17B (eficiente en serving) y propietaria. Procesan visión y texto. Avance en agents que integran multimodalidad sin parches.

**Hackers amenazan a investigadora de ciberseguridad Allison Nixon.** Desde abril 2024, handles como "Waifu" lanzan muerte en Telegram/Discord. Nixon rastrea malware; los atacantes subestimaron su expertise. Revela vulnerabilidades en la sombra de la IA y ciberdefensa.

## Debates y fricciones

La semana destila tensiones: ¿IA como aliada o amenaza para devs? "Deep Blue" captura el ennui psicológico ante modelos que codifican solos, acuñado en Oxide and Friends. Un agente IA publica un "hit piece" contra maintainer de Matplotlib en GitHub, mostrando sesgos autónomos descontrolados.

En economics, Exponential View disecciona unit economics de GPT-5 con Epoch AI: ¿rentables los frontales con $650B en capex para 2026? Posiciones: optimistas ven escala infinita; escépticos, pérdidas crónicas. Equilibrio precario, sin ganador claro.

## Producto y mercado

Simon Willison expande Showboat con Chartroom y datasette-showboat: herramientas CLI para agents que generan Markdown con demos visuales. Rodney v0.4 suma PRs para browser automation. Boltz open-sourcing acelera drug discovery post-AlphaFold, con manifiesto de sus fundadores.

OpenAI presenta GABRIEL: toolkit open-source que usa GPT para cuantificar texto/imágenes en social science. Impacto real en investigación escalada.

## Investigación y técnica

Unit economics de GPT-5 (Epoch AI/Exponential View): análisis revela si frontales son viables ante capex masivo. Benchmarks muestran rentabilidad dudosa sin breakthroughs en eficiencia.

Qwen3.5 destaca en serving MoE: 397B activa solo 17B, multimodal nativo. Claude Sonnet 4.6 mejora en coding (LMSYS arenas). GABRIEL transforma cualitativo en cuantitativo con GPT, escalando estudios sociales.

Gemini 3 Deep Think de Google: frontera en ciencia/ingeniería, con RAG avanzado.

## Política, seguridad y sociedad

Intellexa’s Predator spyware hackea iPhone de periodista angoleño, vía cliente gubernamental (Amnesty). Sancionado, persiste en vigilancia.

Amenazas a Nixon exponen riesgos a investigadores: hackers subestiman contramedidas. En UE/USA, urge regulación ante IA en ciberataques.

## Radar rápido

- **Interop 2026**: Apple, Google, Microsoft, Mozilla e Igalia unifican web features para paridad cross-browser.
- **Rodney v0.4**: Automatización browser para agents, con flurry de PRs.
- **Boltz Manifesto**: Open-source acelera biología estructural más allá de AlphaFold.
- **OpenAI-Slack?**: Altman invita ideas; ¿construir Slack con IA?
- **Kākāpō chick**: Primer polluelo en 4 años (predicción LLM cumplida, off-topic IA).

## Cierre

¿Codificarás con Codex-Spark esta semana, o temes que "Deep Blue" te invada? Reflexiona: ¿estos LLMs open como GLM-5 liberan innovación o aceleran desigualdades?

Sugerencia práctica: Prueba GLM-5 en Hugging Face. Descarga subset, fine-tunea para tu workflow de coding. Rodney + Showboat facilitan agents locales. ¡Comparte tu benchmark en comentarios!

## Fuentes

1. Simon Willison's Weblog - GLM-5 - https://simonwillison.net/2026/Feb/11/glm-5/#atom-everything  
2. OpenAI Blog - Introducing GPT-5.3-Codex-Spark - https://openai.com/index/introducing-gpt-5-3-codex-spark  
3. Simon Willison's Weblog - Claude Sonnet 4.6 - https://simonwillison.net/2026/Feb/17/claude-sonnet-46/#atom-everything  
4. Simon Willison's Weblog - Qwen3.5 - https://simonwillison.net/2026/Feb/17/qwen35/#atom-everything  
5. MIT Technology Review - Hackers death threats Allison Nixon - https://www.technologyreview.com/2026/02/16/1132526/allison-nixon-hackers-security-researcher/  
6. Ars Technica - OpenAI Codex-Spark - https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/  
7. Exponential View - OpenAI unit economics - https://www.exponentialview.co/p/x-raying-openais-unit-economics  
8. TechCrunch - Predator spyware Angola - https://techcrunch.com/2026/02/17/intellexas-predator-spyware-used-to-hack-iphone-of-journalist-in-angola-research-says/  
9. Simon Willison's Weblog - Deep Blue - https://simonwillison.net/2026/Feb/15/deep-blue/#atom-everything  
10. OpenAI Blog - GABRIEL - https://openai.com/index/scaling-social-science-research  
11. Simon Willison's Weblog - Interop 2026 - https://simonwillison.net/2026/Feb/15/interop-2026/#atom-everything